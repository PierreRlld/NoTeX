% Projection linéaire
\noindent $\hookrightarrow$ \underline{\textbf{Représentation non causale - Projection linéaire :}}\par
Sous conditions de moments \footnote{$E[Y^{2}]<+\infty$, $E[\lVert X \rVert^{2}]<+\infty$ et $E[XX']$ inversible = de rang plein. En particulier: \textbf{any level of correlation between covariates except perfect colinearity} : composantes de X linéairement indépendantes mais \textit{n'exclut pas} qu'elles soients corrélées. Si le modèle a une constante et une variable catégorielle il faut exclure une des modalités.}, on a toujours par construction/définition de la représentation linéaire théorique (=projection linéaire orthogonale) orthogonalité des \textit{résidus} de cette représentation non causale avec les régresseurs = pas une hypothèse mais une conséquence.\par
\begin{boxH}
    $Y = X'.\widetilde{\beta} + \widetilde{\varepsilon}$ , $E[X\widetilde{\varepsilon}]=0$ toujours définissable sous conditions de moments.\par
    \begin{itemize}
        \item[\textbf{-}] $\widehat{\beta_{OLS}}$ \redline{estime toujours} $\widetilde{\beta}$ : $\widehat{\beta_{OLS}} \underset{n \to +\infty}{\longrightarrow} \widetilde{\beta}$\par
        \item[\textbf{-}] $X'.\widetilde{\beta}$ meilleure prédiction linéaire de Y par X : $\widetilde{\beta}$ solution MSE.
    \end{itemize}
\end{boxH}

\begin{equation*} 
    \widehat{\beta_{OLS}} \in \underset{\beta}{\mathrm{argmin}} \sum_{i = 1}^{n}{(Y_{i} - X_{i}'.\beta)^{2}} \quad \longleftrightarrow \quad \widetilde{\beta} \in \underset{\beta}{\mathrm{argmin}} \; E[(Y-X'.\beta)^{2}]
\end{equation*}

\bigbreak
% Représentation causale
\noindent $\hookrightarrow$ \underline{\textbf{Représentation causale :}}\par
La représentation causale fait intervenir \ghl{le paramètre causal $\beta_{0}$ qu'on cherche à estimer} : dans cette représentation le \textit{terme d'erreur} n'est pas automatiquement orthogonal au régresseur.\par
\begin{boxH}
    $Y = X'.\beta_{0} + \varepsilon$ , $E[X\varepsilon]\overset{\textbf{\red{?}}}{=}0$\par
    \begin{itemize}
        \item[\textbf{-}] $\beta_{0}$ paramètre causal à estimer.\par
        \item[\textbf{-}] $\varepsilon$ résidu : agrège les facteurs inobservés qui affectent $Y$.
    \end{itemize}
\end{boxH}
Le \ghl{terme d'erreur $\varepsilon$ capte l'hétérogénéité inobservée}, i.e capte les déterminants inobservés qui affectent la variable d'intérêt $Y$ : deux individus avec les mêmes variables explicatives auront néanmoins la plupart du temps des variables expliquées différentes.\par
Avoir orthogonalité ($\rightarrow$ indépendance) entre régresseurs et terme d'erreur est une hypothèse ! C'est \textbf{l'hypothèse d'exogénéité}.

\bigbreak
%Lien
\noindent $\hookrightarrow$ \underline{\textbf{Lien :}}\par
\blue{Sans l'hypothèse d'exogénéité pour la représentation causale, les deux représentations diffèrent} et l'estimateur OLS ne permet pas d'identifier le paramètre causal d'intérêt.\par
En revanche \ghl{avec hypothèse d'exogénéité les deux représentations coïncident} et $\widetilde{\beta} = \beta_{0}$ : $\widehat{\beta_{OLS}}$ qui estime toujours $\widetilde{\beta}$ est donc un estimateur consistant de $\beta_{0}$.\par
En dehors des expériences contrôlées les variables explicatives peuvent parfois être corrélées aux facteurs inobersables et pb d'endogénéité $E[X\varepsilon]\neq 0$.
\bigbreak

