1+1
library(arma2A)
help("TestAutocorr")
help("TestSignificatif")
help("armafit")
library(arma2A)
require(fUnitRoots)
require(aTSA)
require(astsa)
data=read.csv('valeurs_trimestrielles.csv',sep=";")
xp.source <- ts(data[[2]]) #données dans la 2e colonne
source("~/Desktop/Stage 2A/files/indice prix logement paris.R")
data=read.csv('valeurs_trimestrielles.csv',sep=";")
xp.source <- ts(data[[2]]) #données dans la 2e colonne
data=read.csv('valeurs_trimestrielles.csv',sep=";")
xp.source <- ts(data[[2]]) #données dans la 2e colonne
data=read.csv('valeurs_trimestrielles.csv',sep=";")
xp.source <- ts(data[[2]]) #données dans la 2e colonne
xp.source <- ts(data[[2]]) #données dans la 2e colonne
require(fUnitRoots)
require(aTSA)
require(astsa)
data=read.csv('valeurs_trimestrielles.csv',sep=";")
xp.source <- ts(data[[2]]) #données dans la 2e colonne
26*34
install.packages("languageserver")
r.home()
R.home()
install.packages(c("askpass", "astsa", "BBmisc", "blob", "boot", "brew", "broom", "bslib", "cachem", "callr", "car", "checkmate", "class", "cli", "cluster", "codetools", "collections", "colorspace", "commonmark", "cpp11", "crayon", "credentials", "curl", "cyclocomp", "data.table", "dbplyr", "desc", "deSolve", "devtools", "digest", "dplyr", "dtplyr", "evaluate", "fansi", "fastmap", "fBasics", "forecast", "foreign", "fracdiff", "fs", "fUnitRoots", "future", "future.apply", "gargle", "gert", "ggplot2", "gh", "gitcreds", "googledrive", "googlesheets4", "gss", "gtable", "haven", "highr", "hms", "htmltools", "htmlwidgets", "httr", "isoband", "jsonlite", "KernSmooth", "knitr", "labeling", "languageserver", "later", "lattice", "lifecycle", "lintr", "lme4", "locfit", "lubridate", "markdown", "MASS", "Matrix", "MatrixModels", "mgcv", "minqa", "modelr", "nlme", "nnet", "openssl", "openxlsx", "packrat", "parallelly", "pillar", "pkgbuild", "pkgload", "plotly", "plyr", "prettyunits", "processx", "promises", "ps", "purrr", "quantmod", "quantreg", "R.utils", "Rcpp", "RcppArmadillo", "RcppEigen", "readr", "readxl", "rematch", "remotes", "rio", "rlang", "rmarkdown", "roxygen2", "rpart", "rprojroot", "rsconnect", "rstudioapi", "rversions", "sass", "scales", "spatial", "stringi", "stringr", "styler", "survival", "sys", "testthat", "tibble", "tidyr", "tidyverse", "timeDate", "timeSeries", "tinytex", "tseries", "TSstudio", "tzdb", "urca", "usethis", "utf8", "uuid", "vars", "vctrs", "viridis", "viridisLite", "vroom", "waldo", "whisker", "withr", "xfun", "xml2", "xts", "yaml", "zip", "zoo"))
install.packages("ggThemeAssist")
install.packages(vars)
install.packages("vars")
install.packages("BVAR")
install.packages("fbi")
devtools::install_github("cykbennie/fbi")
devtools::install_github("cykbennie/fbi")
source("~/git/NoTeX/#TS/MacroE_ML/DFM1.R", echo=TRUE)
install_github("cykbennie/fbi")
source("~/git/NoTeX/#TS/MacroE_ML/DFM1.R", echo=TRUE)
source("~/git/NoTeX/#TS/MacroE_ML/DFM1.R", echo=TRUE)
install.packages('devtools', repos='http://cran.rstudio.com/')
install.packages(c("bslib", "cluster", "crosstalk", "deSolve", "dplyr", "fBasics", "forecast", "fracdiff", "fUnitRoots", "gert", "gss", "gtools", "htmlwidgets", "httr2", "KernSmooth", "lme4", "Matrix", "MatrixModels", "mgcv", "minqa", "nlme", "quantreg", "R.utils", "RcppArmadillo", "RcppEigen", "shiny", "stringi", "stringr", "tinytex", "tseries", "urca"))
install.packages("remotes")
remotes::install_github("nk027/bvar")
install.packages("mvtnorm")
install.packages("fbi")
install.packages("stats")
install.packages("readr")
install.packages("BVAR")
source("~/git/NoTeX/#TS/MacroE_ML/DFM1.R", echo=TRUE)
install.packages('mvtnorm')
install.packages("mvtnorm")
remotes::install_github("cykbennie/fbi")
source("~/git/NoTeX/#TS/MacroE_ML/DFM1.R", echo=TRUE)
R.home()
file.path(R.home("bin"), "R")
find.packages("forecast")
find.package("forecast")
install.package("BVAR")
install.packages("BVAR")
install.packages("mvtnorm")
library(mvtnorm)
source("~/git/NoTeX/#TS/MacroE_ML/DFM1.R", echo=TRUE)
remotes::install_github("cykbennie/fbi")
library(fbi)
source("~/git/NoTeX/#TS/MacroE_ML/DFM1.R", echo=TRUE)
install.packages("readr")
install.packages("stats")
install.packages("stats")
install.packages("stats")
install.packages("stats")
install.packages("stats")
install.packages("stats")
install.packages("stats")
library(pracma)
source("~/git/NoTeX/#TS/MacroE_ML/DFM1.R", echo=TRUE)
library(vars)
? vars
??vars
cwd
wd
setwd("~/git/NoTeX/#TS/MacroE_ML/td1")
wd
source("~/.active-rstudio-document", echo=TRUE)
source("~/git/NoTeX/#TS/MacroE_ML/td1/functions.R", echo=TRUE)
source("~/git/NoTeX/#TS/MacroE_ML/td1/functions.R", echo=TRUE)
source("~/git/NoTeX/#TS/MacroE_ML/td1/functions.R", echo=TRUE)
source("~/git/NoTeX/#TS/MacroE_ML/td1/DFM1.R", echo=TRUE)
source("~/git/NoTeX/#TS/MacroE_ML/td1/DFM1.R", echo=TRUE)
data <- fredmd(filepath, date_start = NULL, date_end = NULL, transform = TRUE)       ##
library(BVAR)
library(fbi)
## File name of desired FRED-MD vintage ##
filepath <- "https://files.stlouisfed.org/files/htdocs/fred-md/monthly/2015-04.csv"  ##
data <- fredmd(filepath, date_start = NULL, date_end = NULL, transform = TRUE)       ##
library(BVAR)
library(fbi)
## File name of desired FRED-MD vintage ##
filepath <- "https://files.stlouisfed.org/files/htdocs/fred-md/monthly/2015-04.csv"  ##
data <- fredmd(filepath, date_start = NULL, date_end = NULL, transform = TRUE)       ##
library(BVAR)
library(fbi)
source("/Users/prld/git/NoTeX/#TS/MacroE_ML/td1/functions.R")
## File name of desired FRED-MD vintage ##
filepath <- "https://files.stlouisfed.org/files/htdocs/fred-md/monthly/2015-04.csv"  ##
data <- fredmd(filepath, date_start = NULL, date_end = NULL, transform = TRUE)       ##
# Type of transformation performed on each series before factors are
# estimated
#   0 --> no transformation
#   1 --> demean only
#   2 --> demean and standardize
#   3 --> recursively demean and then standardize
DEMEAN <- 2
# Information criterion used to select the number of factors; for more details,
# see auxiliary function factors_em()
#   1 --> information criterion PC_p1
#   2 --> information criterion PC_p2
#   3 --> information criterion PC_p3
jj <- 2
# Maximum number of factors to be estimated; if set to 99, the number of
# factors selected is forced to equal 8
kmax <- 8
# =========================================================================
# PART 1: LOAD AND LABEL DATA
# Variable names
series <- colnames(data[,2:length(data)])
# Transformation numbers (we do not need it because data are already transformed)
#tcode <- data[1,]
# Raw data
rawdata <- data[2:nrow(data),2:length(data)]
# Month/year of the final observation
final_date <- tail(data$date, 1)
dates <- data$date
# T = number of months in the sample
T <- length(dates)
# =========================================================================
# PART 2: PROCESS DATA
# 1. Prepare Missing Data
yt <- rawdata
# 2. Reduce Sample  to usable dates: remove first two months because some
# series have been first differenced
yt <- yt[2:nrow(yt), ]
dates <- dates[3:length(dates)]
# 3. Remove Outliers
result <- remove_outliers(yt)
# =========================================================================
# PART 3: ESTIMATE FACTORS AND COMPUTE R-SQUARED
# 1. Estimate Factors using function "factors_em()"
#   ehat    = difference between data and values of data predicted by the factors
#   Fhat    = set of factors
#   lamhat  = factor loadings
#   ve2     = eigenvalues of X'X
#   x2      = data with missing values replaced from the EM algorithm (but untrasformed)
result_factors <- factors_em(result, kmax, jj, DEMEAN)
ehat <- result_factors$ehat
Fhat <- result_factors$Fhat
lamhat <- result_factors$lamhat
ve2 <- result_factors$ve2
x2 <- result_factors$x2
# 2. Compute R-Squared and marginal R-squared from estimated factors and factor loadings using function "mrsq()"
#   R2      = R-squared for each series for each factor
#   mR2     = marginal R-squared for each series for each factor
#   mR2_F   = marginal R-squared for each factor
#   R2_T    = total variation explained by all factors
#   t10_s   = top 10 series that load most heavily on each factor
#   t10_mR2 = marginal R-squared corresponding to top 10 series
#             that load most heavily on each factor
result_mrsq <- mrsq(Fhat, lamhat, ve2, series)
R2 <- result_mrsq$R2
mR2 <- result_mrsq$mR2
mR2_F <- result_mrsq$mR2_F
R2_T <- result_mrsq$R2_T
t10_s <- result_mrsq$t10_s
t10_mR2 <- result_mrsq$t10_mR2
library(BVAR)
library(fbi)
source("/Users/prld/git/NoTeX/#TS/MacroE_ML/td1/functions.R")
## File name of desired FRED-MD vintage ##
filepath <- "https://files.stlouisfed.org/files/htdocs/fred-md/monthly/2015-04.csv"  ##
data <- fredmd(filepath, date_start = NULL, date_end = NULL, transform = TRUE)       ##
library(BVAR)
library(fbi)
source("/Users/prld/git/NoTeX/#TS/MacroE_ML/td1/functions.R")
## File name of desired FRED-MD vintage ##
filepath <- "https://files.stlouisfed.org/files/htdocs/fred-md/monthly/2015-04.csv"  ##
data <- fredmd(filepath, date_start = NULL, date_end = NULL, transform = TRUE)       ##
# Type of transformation performed on each series before factors are
# estimated
#   0 --> no transformation
#   1 --> demean only
#   2 --> demean and standardize
#   3 --> recursively demean and then standardize
DEMEAN <- 2
# Information criterion used to select the number of factors; for more details,
# see auxiliary function factors_em()
#   1 --> information criterion PC_p1
#   2 --> information criterion PC_p2
#   3 --> information criterion PC_p3
jj <- 2
# Maximum number of factors to be estimated; if set to 99, the number of
# factors selected is forced to equal 8
kmax <- 8
# =========================================================================
# PART 1: LOAD AND LABEL DATA
# Variable names
series <- colnames(data[,2:length(data)])
# Transformation numbers (we do not need it because data are already transformed)
#tcode <- data[1,]
# Raw data
rawdata <- data[2:nrow(data),2:length(data)]
# Month/year of the final observation
final_date <- tail(data$date, 1)
dates <- data$date
# T = number of months in the sample
T <- length(dates)
# =========================================================================
# PART 2: PROCESS DATA
# 1. Prepare Missing Data
yt <- rawdata
# 2. Reduce Sample  to usable dates: remove first two months because some
# series have been first differenced
yt <- yt[2:nrow(yt), ]
dates <- dates[3:length(dates)]
# 3. Remove Outliers
result <- remove_outliers(yt)
# =========================================================================
# PART 3: ESTIMATE FACTORS AND COMPUTE R-SQUARED
# 1. Estimate Factors using function "factors_em()"
#   ehat    = difference between data and values of data predicted by the factors
#   Fhat    = set of factors
#   lamhat  = factor loadings
#   ve2     = eigenvalues of X'X
#   x2      = data with missing values replaced from the EM algorithm (but untrasformed)
result_factors <- factors_em(result, kmax, jj, DEMEAN)
ehat <- result_factors$ehat
Fhat <- result_factors$Fhat
lamhat <- result_factors$lamhat
ve2 <- result_factors$ve2
x2 <- result_factors$x2
# 2. Compute R-Squared and marginal R-squared from estimated factors and factor loadings using function "mrsq()"
#   R2      = R-squared for each series for each factor
#   mR2     = marginal R-squared for each series for each factor
#   mR2_F   = marginal R-squared for each factor
#   R2_T    = total variation explained by all factors
#   t10_s   = top 10 series that load most heavily on each factor
#   t10_mR2 = marginal R-squared corresponding to top 10 series
#             that load most heavily on each factor
result_mrsq <- mrsq(Fhat, lamhat, ve2, series)
R2 <- result_mrsq$R2
mR2 <- result_mrsq$mR2
mR2_F <- result_mrsq$mR2_F
R2_T <- result_mrsq$R2_T
t10_s <- result_mrsq$t10_s
t10_mR2 <- result_mrsq$t10_mR2
View(t10_s)
View(t10_mR2)
# Create a bar plot
# Set the length of the vertical axis
custom_ylim <- c(0, 1)
barplot(R2[,8], names.arg = 1:length(R2[,8]), main = "Importance of Factors: R2", xlab = "Series",
ylab = "R2", ylim = custom_ylim, col = "blue")
source("~/git/NoTeX/#TS/MacroE_ML/td1/Diffusion_Indices.R", echo=TRUE)
View(data)
library(BVAR)
library(fbi)
source("/Users/prld/git/NoTeX/#TS/MacroE_ML/td1/functions.R")
source("/Users/prld/git/NoTeX/#TS/MacroE_ML/td1/factors_em_2.R")
## File name of desired FRED-MD vintage ##
filepath <- "https://files.stlouisfed.org/files/htdocs/fred-md/monthly/2015-04.csv"  ##
data <- fredmd(filepath, date_start = as.Date("1960-01-01"), date_end = NULL, transform = TRUE)       ##
# =========================================================================
# Type of transformation performed on each series before factors are
# estimated
#   0 --> no transformation
#   1 --> demean only
#   2 --> demean and standardize
#   3 --> recursively demean and then standardize
DEMEAN <- 2
# Information criterion used to select the number of factors; for more details,
# see auxiliary function factors_em()
#   1 --> information criterion PC_p1
#   2 --> information criterion PC_p2
#   3 --> information criterion PC_p3
jj <- 2
# Maximum number of factors to be estimated; if set to 99, the number of
# factors selected is forced to equal 8
kmax <- 99
# Select the variables to predict
# 6   : Industrial production (IP)
# ??? : Consumer Price Index  (CPI)
nn <- c(6,114);
#nn <- 6
HH = 12; # number of step ahead to forecast
# =========================================================================
# PART 1: LOAD AND LABEL DATA
# Variable names
series <- colnames(data[,2:length(data)])
# Raw data
rawdata <- data[2:nrow(data),2:length(data)]
# Month/year of the final observation
final_date <- tail(data$date, 1)
dates <- data$date
# T = number of months in the sample
T <- length(dates)
# Number of time points to use in the estimation of the parameter: Rolling scheme
Jwind = 120;
# Starting dates for the out-of-sample evaluation
#start_date = "1970-01-01";
start_date = "1974-01-01";
# =========================================================================
# PART 2: PROCESS DATA
# 1. Prepare Missing Data
#yt <- prepare_missing(rawdata, tcode)
yt <- rawdata
# 2. Reduce Sample  to usable dates: remove first two months because some
# series have been first differenced
#yt <- yt[2:nrow(yt), ]
dates <- dates[2:length(dates)]
dim_yt <- dim(yt)
TT <- dim_yt[1]
NN <- dim_yt[2]
# 3. Remove Outliers
result <- remove_outliers(yt)
dates
start_sample <- which(dates == start_date)  # index of start_date
start_sample
if (Jwind > start_sample) {
stop("the rolling window cannot be larger than the first evaluation sample")
}
j0 <- start_sample - Jwind + 1
x_temp <- yt[j0:start_sample, ]   # The available data at the beginning of the out-of-sample evaluation exercise
# Not the complete matrix X with the complete set of data but only in-sample-data = subsample
x<- remove_outliers(x_temp)       # Remove outliers specific to this particular sample
true <- matrix(NA, nrow = TT - tail(HH, 1) - start_sample, ncol = 2)
RW <- matrix(NA, nrow = TT - tail(HH, 1) - start_sample, ncol = 2)
PC <- matrix(NA, nrow = TT - tail(HH, 1) - start_sample, ncol = 2)
library(stats)
